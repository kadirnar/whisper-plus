{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:07:04.268131Z",
     "start_time": "2023-12-30T03:07:04.254012500Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from whisperplus import LongTextSupportSummarizationPipeline, download_and_convert_to_mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70da1d7846d1cea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:00:01.518414Z",
     "start_time": "2023-12-29T03:00:01.508955Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=F0dffH0aKjA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b57f913781b972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:00:34.581907Z",
     "start_time": "2023-12-29T03:00:27.393803600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 04:00:28,850 - INFO - Downloading started... output\\test.mp3\n",
      "2023-12-29 04:00:34,574 - INFO - Download and conversion successful. File saved at: output\\test.mp3\n"
     ]
    }
   ],
   "source": [
    "audio_path = download_and_convert_to_mp3(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef9430da4cf3eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:00:52.465607500Z",
     "start_time": "2023-12-29T03:00:52.448289800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from whisperplus import SpeechToTextPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51bf9505b0bc398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:01:08.041746300Z",
     "start_time": "2023-12-29T03:01:05.825698100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 04:01:05,824 - INFO - Loading model...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mSpeechToTextPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai/whisper-large-v3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\source\\repos\\whisper-plus\\whisperplus\\pipelines\\whisper.py:17\u001b[0m, in \u001b[0;36mSpeechToTextPipeline.__init__\u001b[1;34m(self, model_id)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel already loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\source\\repos\\whisper-plus\\whisperplus\\pipelines\\whisper.py:40\u001b[0m, in \u001b[0;36mSpeechToTextPipeline.load_model\u001b[1;34m(self, model_id)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mLoads the pre-trained speech recognition model and moves it to the specified device.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    model_id (str): Identifier of the pre-trained model to be loaded.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSpeechSeq2Seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     43\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    568\u001b[0m     )\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:2674\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2670\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2671\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2672\u001b[0m         )\n\u001b[0;32m   2673\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2674\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2675\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2676\u001b[0m         )\n\u001b[0;32m   2678\u001b[0m quantization_method_from_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quantization_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "pipeline = SpeechToTextPipeline(model_id=\"openai/whisper-large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51e14544eb28fe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:02:04.839910400Z",
     "start_time": "2023-12-29T03:02:04.820901200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ad2a795c73ff60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:02:14.431594400Z",
     "start_time": "2023-12-29T03:02:14.352296900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a161ee53e4fee2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:09:25.908096200Z",
     "start_time": "2023-12-30T03:09:25.887029600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from whisperplus import SpeechToTextPipeline, download_and_convert_to_mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1718859712f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:04:46.010625500Z",
     "start_time": "2023-12-29T03:04:45.991830100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=F0dffH0aKjA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abcb0e1a6c136670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:05:02.471677Z",
     "start_time": "2023-12-29T03:04:55.463279300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 04:04:56,994 - INFO - Downloading started... output\\test.mp3\n",
      "2023-12-29 04:05:02,453 - INFO - Download and conversion successful. File saved at: output\\test.mp3\n"
     ]
    }
   ],
   "source": [
    "audio_path = download_and_convert_to_mp3(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fabf1121a838219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:05:16.537877100Z",
     "start_time": "2023-12-29T03:05:15.130432200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 04:05:15,129 - INFO - Loading model...\n",
      "2023-12-29 04:05:16,519 - INFO - Model loaded successfully.\n",
      "2023-12-29 04:05:16,520 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "pipeline = SpeechToTextPipeline(model_id=\"openai/whisper-large-v3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6503a5930af4be6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:14:35.980310Z",
     "start_time": "2023-12-29T03:05:41.167139900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2023-12-29 04:05:48,649 - INFO - Transcribing audio...\n"
     ]
    }
   ],
   "source": [
    "transcript = pipeline(\n",
    "    audio_path=audio_path, model_id=\"openai/whisper-large-v3\", language=\"chinese\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5815eeb98e1d9d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:20:52.281342Z",
     "start_time": "2023-12-29T03:20:52.227246600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各位朋友们今天我刷到了一条视频有一名中国的教师正在课堂上向他的学生讲解民主和选举这方面的事情咱们抛开这位老师所持的立场不谈单就这名老师的这段演讲而言还是非常精彩并且非常生动的他的这番演讲真的引人深思废话不多说我们一起来看一下相关的视频你看我们那个脱欧我们都自己投票那么老实跟你讲英国确实是他自己投票那么当时苏格兰独立的话我们说了是58%的人反对所以苏格兰没独立了但是呢那个叫什么英国脱欧52%的人支持所以是不是他们就脱欧了这套照办到咱们中国来来吧咱们也对那个叫什么台湾要不要独立咱们再投一次票投票的结果是什么同学们如果这一票发到你手上你会怎么做老师给你讲发到你的手上肯定第一反应是我肯定会投祖国统一但是投着投着就会变味为什么彭老师给你们举个例子这个时候投票了一人都有票我妈也有票彭老师对妈妈让你吃点我妈妈跑到大街上去投票这个时候一定有个人敲个大锣子在那里喊这边走这边看大街快点把你选票拿来还猪肉更现实猪肉更现实OK好这一招6亿票过去了为什么我们曾经做过前几年有个调查说中国6亿人口人均收入1000块钱以下对不对最后到了你们这30斤半换了选票到你们彭老师这里怎么可能我是共产党员对不对我是大手教授怎么可能30斤半对不对但是后面这个事情越演越烈对不对最后你来找我彭老师你考虑一下嘛300斤半我当然不愿意但是最后我回去和我老公两个睡了一晚上翻来覆去睡不着第二天两上起来商量全国已经12亿票都投成这个样子了我们两口子反对已经没有用了对不对这个时候我们还是现实一点吧两口子加在一起701斤猪肉一家人今年的生活费都可以解决了最后我们也会投我们也会投下这么一票最后的结果是13亿票支持台湾独立所以同事们从这个故事里面听得懂了吗我们是发展中国家我们的人一个月才挣五六千块钱我们国家本科生率才15%左右而英国美国他们的人均GDP是我们的五倍十倍二十倍他们的本科生率是50%80%在他们国家你想要经济操纵政治成本太高了那么通过这种方式台湾独立香港要不要独立吗澳门要不要独立吗新疆要不要独立西藏要不要独立没有说新疆人民想独立吗新疆要不要独立西藏要不要独立没有说新疆人民想独立西藏人民要独立有职业的独立的政客你懂了没有职业三风点鬼火的当我们分裂成三十四大驼的时候当我们四川省变成四川人民共和国的时候当我们你觉得以我们四川省的这个能力有没有办法什么航空母舰北斗导航有没有办法歼20轰20虽然是我们成都生产的但是有没有那个国家经济去支持我们继续往下做这个时候我跟你讲才会让你知道你当年的那三斤半猪肉吃的有多么贵估计你还不知道因为你看不懂这背后的逻辑刚才的这名教师之所以给学生上这堂课是想告诉学生们民主和选举会将中国人民带入万劫不复很显然他所持的这份观点与立场与咱们截然不同但是刚才他这番发言并非一无是处有些朋友可能会觉得他的演讲非常可笑中国人谈论民主谈论选举这不就和太监谈论性生活是一样的吗中国人哪有选票啊其实并不是这样中国人是有选票的我虽然没有参加过选举但是我身边很多亲朋好友都参加过像是选区人大代表选村长等等等等中国人参加选举流程大概是这样的你到了社区聚会以后会有三个人名供你选择张三李四王五至于他们究竟是谁你也不知道也没有人向你介绍社区的工作人员会告诉你选张三选张三有纪念品于是你投了张三一票以后会得到一些凉油米面毛巾牙刷类似的生活用品总价值大概是二三十块钱吧所以刚才这位教师举了一个例子三斤半猪肉就可以让一个中国人出卖自己的选举权利这个例子非常写实并不夸张所以说嘛仔细想一想以现如今中国人民所接受的教育来看如果一夜之间突然民主啊突然有了选票或许会真的走向万劫不复当然了我并不是同意这位教师的观点我认为身为一名人民教师应该告诉孩子们教会孩子们自己手中的这份民主权利究竟有多么重要如果滥用这份民主权力出卖这份民主权力才会使中国人民走向万劫不复这就是我想说的欢迎大家留下自己的意见谢谢大家\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a742759b155c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:22:34.229593500Z",
     "start_time": "2023-12-29T03:22:34.221506600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from whisperplus.pipelines.long_text_support_summarization import LongTextSupportSummarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba8bae9ad5ddc66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:23:11.089486100Z",
     "start_time": "2023-12-29T03:23:02.484116600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 04:23:02,483 - INFO - Initializing Text Summarization Pipeline\n",
      "2023-12-29 04:23:03,446 - INFO - Loading model...\n",
      "2023-12-29 04:23:11,077 - INFO - Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "summarizer = LongTextSupportSummarizationPipeline(model_id=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6605f1ab6b7ceb5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:27:36.374293700Z",
     "start_time": "2023-12-29T03:23:34.234863Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3191 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer.summarize(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d9bfdb5c53f1b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:40:47.395325Z",
     "start_time": "2023-12-29T03:40:47.357223500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummary_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "print(summary[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b104166e43cf56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:41:22.168033400Z",
     "start_time": "2023-12-29T03:41:22.141320600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’s’ ‘’’ ‘”’   ’. ’”. ”. .  ‘. “. ‘.” ’ ’.’ '’,’'’;. ‚’: ‘'”: “” ’(”)’-”,”-  ”(’)”;.‚ : ”” (”),� ’s’ ‘’’ ‘”’   ’. ’”. ”. .  .” ’.’ '’,’,.’;. “”,”,.” “’: ”:’'’-”-’(’)’ (’)(’),’('’):’[’]’ [’],’,'’',   “20’20”  �� “”” “’’ ‘’ ‘” ’. ’”.  ’: “I’m sorry, I’ve got to go.’,’ she said. “,” she said, “but I can’t go home.”, ”’;. ‚”: ‘I�’slammed. . ”:   ’s’  ‘’’ ‘ ’. ’”. “” “’ ”’: ‘I’m sorry,’ she said. ‘You’re not allowed to say that.’ '’ She said. '‘I don’t have to say it.” ‘'’\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3599dca7278ac69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:52:40.196005Z",
     "start_time": "2023-12-29T03:52:40.179273Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各位朋友们今天我刷到了一条视频有一名中国的教师正在课堂上向他的学生讲解民主和选举这方面的事情咱们抛开这位老师所持的立场不谈单就这名老师的这段演讲而言还是非常精彩并且非常生动的他的这番演讲真的引人深思废话不多说我们一起来看一下相关的视频你看我们那个脱欧我们都自己投票那么老实跟你讲英国确实是他自己投票那么当时苏格兰独立的话我们说了是58%的人反对所以苏格兰没独立了但是呢那个叫什么英国脱欧52%的人支持所以是不是他们就脱欧了这套照办到咱们中国来来吧咱们也对那个叫什么台湾要不要独立咱们再投一次票投票的结果是什么同学们如果这一票发到你手上你会怎么做老师给你讲发到你的手上肯定第一反应是我肯定会投祖国统一但是投着投着就会变味为什么彭老师给你们举个例子这个时候投票了一人都有票我妈也有票彭老师对妈妈让你吃点我妈妈跑到大街上去投票这个时候一定有个人敲个大锣子在那里喊这边走这边看大街快点把你选票拿来还猪肉更现实猪肉更现实OK好这一招6亿票过去了为什么我们曾经做过前几年有个调查说中国6亿人口人均收入1000块钱以下对不对最后到了你们这30斤半换了选票到你们彭老师这里怎么可能我是共产党员对不对我是大手教授怎么可能30斤半对不对但是后面这个事情越演越烈对不对最后你来找我彭老师你考虑一下嘛300斤半我当然不愿意但是最后我回去和我老公两个睡了一晚上翻来覆去睡不着第二天两上起来商量全国已经12亿票都投成这个样子了我们两口子反对已经没有用了对不对这个时候我们还是现实一点吧两口子加在一起701斤猪肉一家人今年的生活费都可以解决了最后我们也会投我们也会投下这么一票最后的结果是13亿票支持台湾独立所以同事们从这个故事里面听得懂了吗我们是发展中国家我们的人一个月才挣五六千块钱我们国家本科生率才15%左右而英国美国他们的人均GDP是我们的五倍十倍二十倍他们的本科生率是50%80%在他们国家你想要经济操纵政治成本太高了那么通过这种方式台湾独立香港要不要独立吗澳门要不要独立吗新疆要不要独立西藏要不要独立没有说新疆人民想独立吗新疆要不要独立西藏要不要独立没有说新疆人民想独立西藏人民要独立有职业的独立的政客你懂了没有职业三风点鬼火的当我们分裂成三十四大驼的时候当我们四川省变成四川人民共和国的时候当我们你觉得以我们四川省的这个能力有没有办法什么航空母舰北斗导航有没有办法歼20轰20虽然是我们成都生产的但是有没有那个国家经济去支持我们继续往下做这个时候我跟你讲才会让你知道你当年的那三斤半猪肉吃的有多么贵估计你还不知道因为你看不懂这背后的逻辑刚才的这名教师之所以给学生上这堂课是想告诉学生们民主和选举会将中国人民带入万劫不复很显然他所持的这份观点与立场与咱们截然不同但是刚才他这番发言并非一无是处有些朋友可能会觉得他的演讲非常可笑中国人谈论民主谈论选举这不就和太监谈论性生活是一样的吗中国人哪有选票啊其实并不是这样中国人是有选票的我虽然没有参加过选举但是我身边很多亲朋好友都参加过像是选区人大代表选村长等等等等中国人参加选举流程大概是这样的你到了社区聚会以后会有三个人名供你选择张三李四王五至于他们究竟是谁你也不知道也没有人向你介绍社区的工作人员会告诉你选张三选张三有纪念品于是你投了张三一票以后会得到一些凉油米面毛巾牙刷类似的生活用品总价值大概是二三十块钱吧所以刚才这位教师举了一个例子三斤半猪肉就可以让一个中国人出卖自己的选举权利这个例子非常写实并不夸张所以说嘛仔细想一想以现如今中国人民所接受的教育来看如果一夜之间突然民主啊突然有了选票或许会真的走向万劫不复当然了我并不是同意这位教师的观点我认为身为一名人民教师应该告诉孩子们教会孩子们自己手中的这份民主权利究竟有多么重要如果滥用这份民主权力出卖这份民主权力才会使中国人民走向万劫不复这就是我想说的欢迎大家留下自己的意见谢谢大家\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0a83a0d07cba27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:53:47.111434100Z",
     "start_time": "2023-12-29T03:53:07.444893300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 04:53:07,443 - INFO - Initializing Text Summarization Pipeline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77baa144334c4e36a99da8cb8673b80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fe261598dd41edbadd8cc1efc65785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28dce988d85429381e1ddd507844c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f98b29c57b4c62aeacb8eb00df6508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 04:53:09,181 - INFO - Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f225e4ccae401598d8fefc9e500f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The model 'BertForMaskedLM' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
      "2023-12-29 04:53:47,092 - INFO - Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "summarizer = LongTextSupportSummarizationPipeline(model_id=\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4c1894e2ac8e387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:55:14.750791700Z",
     "start_time": "2023-12-29T03:55:09.963103700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer.summarize(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acd4e40c78e0f692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T01:38:33.378493200Z",
     "start_time": "2023-12-30T01:38:33.362392900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "里里里里我刷到了一条视频有一名中国的教师今天我刷到了一条视频有一名中国的教师正在课堂上这堂课我刷我刷我刷我刷到了我刷到了我刷到了我刷到了咱们中国今天我刷到了一条视频有一名中国的教师正在课堂上我刷到咱们中国来来来吧咱们也对那个叫什么台湾要不要独立咱们再投一次票投票的结果是什么同学们如果这一票发到你手上你会怎么做老师给你讲发到你的手上肯定第一反应第一反应是我肯定第一反应是我肯定会投祖国统一但是投祖国统一但是\n"
     ]
    }
   ],
   "source": [
    "print(summary[0][\"summary_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d81e6628d5e2144c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T03:55:53.187571Z",
     "start_time": "2023-12-29T03:55:53.170547300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各 位 朋 友 们 今 天 我 刷 到 了 一 条 视 频 有 一 名 中 国 的 教 师 正 在 课 堂 上 向 他 的 学 生 讲 解 民 主 和 选 举 这 方 面 的 事 情 咱 们 抛 开 这 位 老 师 所 持 的 立 场 不 谈 单 就 这 名 老 师 的 这 段 演 讲 而 言 还 是 非 常 精 彩 并 且 非 常 生 动 的 他 的 这 番 演 讲 真 的 引 人 深 思 废 话 不 多 说 我 们 一 起 来 看 一 下 相 关 的 视 频 你 看 我 们 那 个 脱 欧 我 们 都 自 己 投 票 那 么 老 实 跟 你 讲 英 国 确 实 是 他 自 己 投 票 那 么 当 时 苏 格 兰 独 立 的 话 我 们 说 了 是 58 % 的 人 反 对 所 以 苏 格 兰 没 独 立 了 但 是 呢 那 个 叫 什 么 英 国 脱 欧 52 % 的 人 支 持 所 以 是 不 是 他 们 就 脱 欧 了 这 套 照 办 到 咱 们 中 国 来 来 吧 咱 们 也 对 那 个 叫 什 么 台 湾 要 不 要 独 立 咱 们 再 投 一 次 票 投 票 的 结 果 是 什 么 同 学 们 如 果 这 一 票 发 到 你 手 上 你 会 怎 么 做 老 师 给 你 讲 发 到 你 的 手 上 肯 定 第 一 反 应 是 我 肯 定 会 投 祖 国 统 一 但 是 投 着 投 着 就 会 变 味 为 什 么 彭 老 师 给 你 们 举 个 例 子 这 个 时 候 投 票 了 一 人 都 有 票 我 妈 也 有 票 彭 老 师 对 妈 妈 让 你 吃 点 我 妈 妈 跑 到 大 街 上 去 投 票 这 个 时 候 一 定 有 个 人 敲 个 大 锣 子 在 那 里 喊 这 边 走 这 边 看 大 街 快 点 把 你 选 票 拿 来 还 猪 肉 更 现 实 猪 肉 更 现 实 好 这 一 招 6 亿 票 过 去 了 为 什 么 我 们 曾 经 做 过 前 几 年 有 个 调 查 说 中 国 6 亿 人 口 人 均 收 入 1000 块 钱 以 下 对 不 对 最 后 到 了 你 们 这 30 斤 半 换 了 那 选 票 到 你 们 彭 老 师 这 里 怎 么 可 能 我 是 共 产 党 员 对 不 对 我 是 大 手 教 授 怎 么 可 能 30 斤 半 对 不 对 但 是 后 面 这 个 事 情 越 演 越 烈 对 不 对 最 后 你 来 找 我 彭 老 师 你 考 虑 一 下 嘛 300 斤 半 我 当 然 不 愿 意 但 是 最 后 我 回 去 和 我 老 公 两 个 睡 了 一 晚 上 翻 来 覆 去 睡 不 着 第 二 天 两 上 起 来 商 量 全 国 已 经 12 亿 票 都 投 成 这 个 样 子 了 我 们 两 口 子 反 对 已 经 没 有 用 了 对 不 对 这 个 时 候 我 们 还 是 现 实 一 点 吧 两 口 子 加 在 一 起 701 斤 猪 肉 一 家 人 今 年 的 生 活 费 都 可 以 解 决 了 最 后 我 们 也 会 投 我 们 也 会 投 下 这 么 一 票 最 后 的 结 果 是 13 亿 票 支 持 台 湾 独 立 所 以 同 事 们 从 这 个 故 事 里 面 听 得 懂 了 吗 我 们 是 发 展 中 国 家 我 们 的 人 一 个 月 才 挣 五 六 千 块 钱 我 们 国 家 本 科 生 率 才 15 % 左 右 而 英 国 美 国 他 们 的 人 均 是 我 们 的 五 倍 十 倍 二 十 倍 他 们 的 本 科 生 率 是 50 % 80 % 在 他 们 国 家 你 想 要 经 济 操 纵 政 治 成 本 太 高 了 那 么 通 过 这 种 方 式 台 湾 独 立 香 港 要 不 要 独 立 吗 澳 门 要 不 要 独 立 吗 新 疆 要 不 要 独 立 西 藏 要 不 要 独 立 没 有 说 新 疆 人 民 想 独 立 吗 新 疆 要 不 要 独 立 西 藏 要 不 要 独 立 没 有 说 新 疆 人 民 想 独 立 西 藏 人 民 要 独 立 有 职 业 的 独 立 的 政 客 你 懂 了 没 有 职 业 三 风 点 鬼 火 的 当 我 们 分 裂 成 三 十 四 大 驼 的 时 候 当 我 们 四 川 省 变 成 四 川 人 民 共 和 国 的 时 候 当 我 们 你 觉 我 得 以 我 们 四 川 省 的 这 个 能 力 有 没 有 办 法 什 么 航 空 母 舰 北 斗 导 航 有 没 有 办 法 歼 20 轰 20 虽 然 是 我 们 成 都 生 产 的 但 是 有 没 有 那 个 国 家 经 济 去 支 持 我 们 继 续 往 下 做 这 个 时 候 我 跟 你 讲 才 会 让 你 知 道 你 当 年 的 那 三 斤 半 猪 肉 吃 的 有 多 么 贵 估 计 你 还 不 知 道 因 为 你 看 不 懂 这 背 后 的 逻 辑 刚 才 的 这 名 教 师 之 所 以 给 学 生 上 这 堂 课 是 想 告 诉 学 生 们 民 主 和 选 举 会 将 中 国 人 民 带 入 万 劫 不 复 很 显 然 他 所 持 的 这 份 观 点 与 立 场 与 咱 们 截 然 不 同 但 是 刚 才 他 这 番 发 言 并 非 一 无 是 处 有 些 朋 友 可 能 会 觉 得 他 的 演 讲 非 常 可 笑 中 国 人 谈 论 民 主 谈 论 选 举 这 不 就 和 太 监 谈 论 性 生 活 是 一 样 的 吗 中 国 人 哪 有 选 票 啊 其 实 并 不 是 这 样 中 国 人 是 有 选 票 的 我 虽 然 没 有 参 加 过 选 举 但 是 我 身 边 很 多 亲 朋 好 友 都 参 加 过 像 是 选 区 人 大 代 表 选 村 长 等 等 等 等 中 国 人 参 加 选 举 流 程 大 概 是 这 样 的 你 到 了 社 区 聚 会 以 后 会 有 三 个 人 名 供 你 选 择 张 三 李 四 王 五 至 于 他 们 究 竟 是 谁 你 也 不 知 道 也 没 有 人 向 你 介 绍 社 区 的 工 作 人 员 会 告 诉 你 选 张 三 选 张 三 有 纪 念 品 于 是 你 投 了 张 三 一 票 以 后 会 得 到 一 些 凉 油 米 面 毛 巾 牙 刷 类 似 的 生 活 用 品 总 价 值 大 概 是 二 三 十 块 钱 吧 所 以 刚 才 这 位 教 师 举 了 一 个 例 子 三 斤 半 猪 肉 就 可 以 让 一 个 中 国 人 出 卖 自 己 的 选 举 权 利 这 这 个 例 子 非 常 写 实 并 不 夸 张 所 以 说 嘛 仔 细 想 一 想 以 现 如 今 中 国 人 民 所 接 受 的 教 育 来 看 如 果 一 夜 之 间 突 然 民 主 啊 突 然 有 了 选 票 或 许 会 真 的 走 向 万 劫 不 复 当 然 了 我 并 不 是 同 意 这 位 教 师 的 观 点 我 认 为 身 为 一 名 人 民 教 师 应 该 告 诉 孩 子 们 教 会 孩 子 们 自 己 手 中 的 这 份 民 主 权 利 究 竟 有 多 么 重 要 如 果 滥 用 这 份 民 主 权 力 出 卖 这 份 民 主 权 力 才 会 使 中 国 人 民 走 向 万 劫 不 复 这 就 是 我 想 说 的 欢 迎 大 家 留 下 自 己 的 意 见 谢 谢 大 家 。\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c6fe2d7059f907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T12:54:42.362334600Z",
     "start_time": "2023-12-29T12:44:44.028645100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 13:44:44,028 - INFO - Initializing Text Summarization Pipeline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2379cf858f714eaab1654567da413882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b7972168c48fcb5dde5327b6f0023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d87a48f86742d287d17586a9ba26d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 13:44:47,786 - INFO - Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a27462c46a145468f68c6d0827b1ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fd1a5bef0246ea9671fa32e35cf131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/205 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 13:54:42,271 - INFO - Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "summarizer = LongTextSupportSummarizationPipeline(model_id=\"facebook/mbart-large-cc25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4894181067b4755a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T01:37:20.377052Z",
     "start_time": "2023-12-30T01:35:09.945562200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "summary = summarizer.summarize(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffefa584cf694046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T15:38:38.800879400Z",
     "start_time": "2023-12-30T15:38:38.776763100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan Semiconductor Manufacturing Company, or TSMC, makes the world's most advanced AI chips. TSMC's chip fabrication facilities, or fabs, are located on the western coast of Taiwan, just 110 miles from mainland China. Taiwan's central role in the global semiconductor industry is often referred to as its silicon shield. If or when China invades Taiwan, TSMC's fabs will, in all likelihood, go offline. This will mean that no more cutting edge AI chips will be able to be produced anywhere. Let us hope that diplomacy prevails. Progress in AI would be profoundly disrupted. We need to find a way to make sure we don't lose our way.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8045f8a31cb459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:07:30.820533500Z",
     "start_time": "2023-12-30T03:07:30.807532Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=AJGrdtKT3LM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479a9db0ad11e5b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:07:43.010069900Z",
     "start_time": "2023-12-30T03:07:33.170584600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 04:07:34,660 - INFO - Downloading started... output\\test.mp3\n",
      "2023-12-30 04:07:42,995 - INFO - Download and conversion successful. File saved at: output\\test.mp3\n"
     ]
    }
   ],
   "source": [
    "audio_path = download_and_convert_to_mp3(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6dfe5241c741520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:09:40.034798400Z",
     "start_time": "2023-12-30T03:09:38.908467200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 04:09:38,908 - INFO - Loading model...\n",
      "2023-12-30 04:09:40,018 - INFO - Model loaded successfully.\n",
      "2023-12-30 04:09:40,019 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "pipeline = SpeechToTextPipeline(model_id=\"openai/whisper-large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7b3be3fc4e86c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:48:45.135875600Z",
     "start_time": "2023-12-30T03:09:42.761359900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2023-12-30 04:09:49,832 - INFO - Transcribing audio...\n"
     ]
    }
   ],
   "source": [
    "transcript = pipeline(\n",
    "    audio_path=audio_path, model_id=\"openai/whisper-large-v3\", language=\"english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3328d0fda2d7b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:05:56.959134Z",
     "start_time": "2023-12-30T03:05:38.809795800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TWAHMK\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyannote\\audio\\core\\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "C:\\Users\\TWAHMK\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch_audiomentations\\utils\\io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "from whisperplus.pipelines.summarization import TextSummarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd3cdd92804702e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T02:51:22.032398100Z",
     "start_time": "2023-12-30T02:51:19.655593200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 03:51:19,656 - INFO - Initializing Text Summarization Pipeline\n",
      "2023-12-30 03:51:19,661 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "summarizer = TextSummarizationPipeline(model_id=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a560b235b848a977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:08:12.972866900Z",
     "start_time": "2023-12-30T03:08:12.933562900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcript' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtranscript\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transcript' is not defined"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c33291dc58bc65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T15:37:48.568148800Z",
     "start_time": "2023-12-30T15:36:38.688236200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1969 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 130, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer.summarize(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "607e034fddc3b9ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T15:36:22.499331100Z",
     "start_time": "2023-12-30T15:36:22.469741900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from whisperplus.pipelines.long_text_support_summarization import LongTextSupportSummarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c97ddd4fcd7506b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T15:36:35.032923Z",
     "start_time": "2023-12-30T15:36:27.781425600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 16:36:27,781 - INFO - Initializing Text Summarization Pipeline\n",
      "2023-12-30 16:36:28,364 - INFO - Loading model...\n",
      "2023-12-30 16:36:35,010 - INFO - Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "summarizer = LongTextSupportSummarizationPipeline(model_id=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db2b6c1ecf15a210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:01:51.432148900Z",
     "start_time": "2023-12-30T03:01:51.412925800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '！' (U+FF01) (3842055240.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ！export CUDA_LAUNCH_BLOCKING=1\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '！' (U+FF01)\n"
     ]
    }
   ],
   "source": [
    "！export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95d9147386ff3489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:02:28.452770200Z",
     "start_time": "2023-12-30T03:02:28.318332400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6952c8c489764ed3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T03:04:06.345561800Z",
     "start_time": "2023-12-30T03:04:06.217335300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!set CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76ef49c9de9e7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T15:35:01.906996400Z",
     "start_time": "2023-12-30T15:35:01.888226300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The following statement is utterly ludicrous. It is also true. The world's most important advanced technology is nearly all produced in a single facility. What's more, that facility is located in one of the most geopolitically fraught areas on Earth, an area in which many analysts believe that war is inevitable within the decade. The future of artificial intelligence hangs in the balance. The Taiwan Semiconductor Manufacturing Company, or TPUs, AMD's GPUs, the AI chips from Microsoft, Amazon, Tesla, Cerebrus, Samba Nova, and every other credible competitor. Modern artificial intelligence simply would not be possible without these highly specialized chips. Little wonder, then, that Time Magazine recently described TSMC as quote, the world's most important company that you've probably never heard of. Nvidia CEO Jensen Huang put it more colorfully saying quote, basically there is air and TSMC. TSMC's chip fabrication facilities, or fabs, the buildings where chips are physically built, is located on the western coast of Taiwan, a mere 110 miles from mainland China. In this map, Taiwan is shown in orange and China is shown in green. Today, China and Taiwan are nearer to the brink of war than they have been in decades. Many policymakers in Washington predict that China will invade Taiwan within the next five years. A China-Taiwan conflict would be devastating for many reasons. Aside from the heavy human toll, one underappreciated consequence is that it would paralyze the global AI ecosystem. Put simply, the entire field of artificial intelligence faces an astonishingly precarious single point of failure in Taiwan. Amid all of the fervor around AI today, this fact is not widely enough appreciated. If you are working on or are interested in AI, you need to be paying attention. How did we get here, and what can we do about it? Let's start with a brief whirlwind overview of the chip industry. Semiconductors, or chips, are the most complex object in the world that humanity knows how to mass produce. Making semiconductors requires the world's purest metals, the world's most expensive machinery, legions of highly specialized engineers, and atom-level manufacturing precision. It is important to distinguish between two different types of chip companies. First, fabless chipmakers, which design but do not manufacture their own chips. And second, foundries, which manufacture chips designed by other companies. Almost every well-known chip company today is Fabless, from NVIDIA to AMD to Qualcomm. These companies do not produce their own chips. Instead, they design chips, and then they rely on foundries like TSMC to actually manufacture those chips for them. There are only three companies in the world today that are capable of manufacturing chips anywhere near the leading edge of semiconductor technology. TSMC, Samsung, and Intel. Of those three, only one can reliably produce the world's most advanced AI chips, including chips like NVIDIA's H100 GPUs. That one company is TSMC. As of this morning, TSMC's market capitalization was $470 billion, making it the 13th largest company in the world, larger than ExxonMobil, JPMorgan Chase, or Walmart. How has TSMC become such a dominant force? The short answer is that powerful economies of scale exist in the world of chip fabrication, leading inexorably to winner-take-all dynamics. of chip fabrication, leading inexorably to winner-take-all dynamics. Making advanced semiconductors requires tremendous upfront and ongoing capital expenditure. In 2021, TSMC announced that it would invest $100 billion over the next three years to continue expanding its fabrication capabilities. No other company in the world can justify that level of investment. TSMC can, because of the sheer volume of chips that it produces, far more than any other company in the world. A related dynamic that helps explain TSMC's unassailable position is what has come to be known as the TSMC Grand Alliance. TSMC has invested heavily over decades to develop deep partnerships with dozens of companies across the semiconductor supply chain, from software providers like Cadence to equipment manufacturers like ASML to chip designers like NVIDIA. In turn, these companies have developed their own products in accordance with TSMC's roadmap, leading to powerful lock-in. In summary, a combination of economies of scale, network effects, and unrivaled specialization have made TSMC irreplaceable, and have made the entire world deeply, precariously dependent upon it. This brings us to the present delicate geopolitical moment. Last October, the Biden administration took the dramatic step of banning the export of all high-end AI chips to any entity in China. The rationale behind these measures was clear. To leverage US control of the global semiconductor supply chain as a choke point to handicap China's AI capabilities. The U.S. government is currently formulating expansions to this policy. At the same time, the U.S. is taking steps to reduce its reliance on chip fabrication facilities located in East Asia. In late 2022, TSMC announced that it would invest $40 billion to build two new state-of-the-art fabs in the United States, in Arizona. The first of these two fabs is slated to begin production in 2025. Bringing advanced chip production to U.S. oil will help mitigate the AI industry's absolute dependence on Taiwan-based fabs. But the Arizona fabs will not solve everything. Their production capacity will be modest, representing less than 5% of TSMC's total global output. And the most advanced semiconductor production capabilities and technologies will remain in Taiwan. So, where might things go from here? the most advanced semiconductor production capabilities and technologies will remain in Taiwan. So, where might things go from here? Let's briefly consider a few possibilities on this three-dimensional chessboard. Let's start with the optimistic scenario. Taiwan's central role in the global semiconductor industry is often referred to as its silicon shield. The basic theory is this. Because China depends so heavily on Taiwan for the chips that it needs to keep its own economy running, China will stop short of invading Taiwan and putting TSMC's production at risk. And because the rest of the world is likewise so dependent on TSMC, the United States and other powers will go to great lengths to protect the island and defend its sovereignty. Under this theory, while China may continue to build out its military and engage in cross-strait saber-rattling, it will stop short of kinetic action against Taiwan. But the Silicon Shield is just a theory, not a guarantee. What would happen if China were to move decisively to retake Taiwan? TSMC's fabs would almost certainly be rendered inoperative. It is conceivable that the Taiwanese or even the U.S. military would preemptively destroy the fabs in order to prevent the CCP from taking control of this valuable strategic resource. Even if the physical buildings were to remain undamaged after a Chinese invasion, it is unrealistic that the CCP would be able to continue operating the fabs to produce cutting-edge chips. Keeping leading-edge fabs running requires ongoing and deep partnership with organizations across the global semiconductor ecosystem, as well as a steady inflow of materials, equipment, and services. These would be denied to an invading power. Let me say this one more time. If or when China invades Taiwan, TSMC's fabs will, in all likelihood, go offline. This will mean that no more NVIDIA H100s or any other cutting edge AI chips will be able to be produced anywhere in the world. What would this mean for the world of AI? After TSMC, the company best positioned to step up and produce cutting edge AI chips is Samsung. Samsung is currently the only company in the world other than TSMC that is capable of producing three nanometer chips, today's cutting-edge technology. But Samsung's production capabilities are far inferior to TSMC's today. In a best-case scenario, it would take Samsung years to scale up to TSMC's current AI chip yields and volumes. This brings us to America's former chip champion, Intel. It was hardly a decade ago that Intel's chip manufacturing capabilities were the envy of the world. But in recent years, Intel has fallen behind. The company struggled mightily in its transition to both 10 nanometer and 7 nanometer node technologies, even resorting to outsourcing some of its leading-edge production to TSMC. Under CEO Pat Gelsinger, Intel aspires to regain its chipmaking supremacy with an ambitious plan to leapfrog TSMC and begin producing 2 nanometer chips in 2024. Whether this ambitious plan will actually prove achievable, however, remains to be seen. Before we despair too much, let us note a couple encouraging points. First, keep in mind that a considerable stock of AI chips already exists in the world, and even in a worst-case scenario, these chips would remain in use. And even in a worst-case scenario, these chips would remain in use. Second, while the most advanced AI chips, like Google's TPUs or NVIDIA's H100s, can only be manufactured in Taiwan, there are many fabs around the world, from the US to Europe to Israel, that are capable of producing lagging-edge logic chips at scale. Though they are far less powerful than today's leading AI chips, these previous generation chips could be used in a pinch to support some AI computing workloads. Ultimately, though, it would be devastating for humanity to lose its ability to produce the chips that power today's cutting-edge artificial intelligence. Progress in AI would be profoundly disrupted. Let us hope that diplomacy prevails.\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "424ddfd24dca12cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T15:39:16.563771800Z",
     "start_time": "2023-12-30T15:39:16.532798900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan Semiconductor Manufacturing Company, or TSMC, makes the world's most advanced AI chips. TSMC's chip fabrication facilities, or fabs, are located on the western coast of Taiwan, just 110 miles from mainland China. Taiwan's central role in the global semiconductor industry is often referred to as its silicon shield. If or when China invades Taiwan, TSMC's fabs will, in all likelihood, go offline. This will mean that no more cutting edge AI chips will be able to be produced anywhere. Let us hope that diplomacy prevails. Progress in AI would be profoundly disrupted. We need to find a way to make sure we don't lose our way.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1530771c1d56e27e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
